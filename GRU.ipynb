{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5baa705e-488d-4322-b627-fd08278e57ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4,3) (4,4) (4,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 141\u001b[0m\n\u001b[0;32m    138\u001b[0m y_train \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28msum\u001b[39m(seq[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m X_train]\n\u001b[0;32m    140\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m--> 141\u001b[0m gru\u001b[38;5;241m.\u001b[39mtrain(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m# Predict\u001b[39;00m\n\u001b[0;32m    144\u001b[0m test_seq \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(input_size) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(sequence_length)]\n",
      "Cell \u001b[1;32mIn[1], line 119\u001b[0m, in \u001b[0;36mGRU.train\u001b[1;34m(self, X, y, epochs)\u001b[0m\n\u001b[0;32m    117\u001b[0m     loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum((y_pred \u001b[38;5;241m-\u001b[39m y[i]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    118\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m--> 119\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackward(y[i])\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_loss\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(X)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 81\u001b[0m, in \u001b[0;36mGRU.backward\u001b[1;34m(self, target)\u001b[0m\n\u001b[0;32m     79\u001b[0m dz_raw \u001b[38;5;241m=\u001b[39m dz \u001b[38;5;241m*\u001b[39m dsigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWz \u001b[38;5;241m@\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mUz \u001b[38;5;241m@\u001b[39m h_prev \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbz)\n\u001b[0;32m     80\u001b[0m dWz \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m dz_raw \u001b[38;5;241m@\u001b[39m x\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m---> 81\u001b[0m dUz \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m dz_raw \u001b[38;5;241m@\u001b[39m h_prev\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m     82\u001b[0m dbz \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m dz_raw\n\u001b[0;32m     84\u001b[0m h_tilde_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWh \u001b[38;5;241m@\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mUh \u001b[38;5;241m@\u001b[39m (r \u001b[38;5;241m*\u001b[39m h_prev) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbh\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,3) (4,4) (4,3) "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def dsigmoid(x):\n",
    "    s = sigmoid(x)\n",
    "    return s * (1 - s)\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def dtanh(x):\n",
    "    return 1 - tanh(x) ** 2\n",
    "\n",
    "class GRU:\n",
    "    def __init__(self, input_size, hidden_size, output_size, lr=0.01):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.lr = lr\n",
    "\n",
    "        # Update gate\n",
    "        self.Wz = np.random.randn(hidden_size, input_size) * 0.1\n",
    "        self.Uz = np.random.randn(hidden_size, hidden_size) * 0.1\n",
    "        self.bz = np.zeros((hidden_size, 1))\n",
    "\n",
    "        # Reset gate\n",
    "        self.Wr = np.random.randn(hidden_size, input_size) * 0.1\n",
    "        self.Ur = np.random.randn(hidden_size, hidden_size) * 0.1\n",
    "        self.br = np.zeros((hidden_size, 1))\n",
    "\n",
    "        # Candidate hidden state\n",
    "        self.Wh = np.random.randn(hidden_size, input_size) * 0.1\n",
    "        self.Uh = np.random.randn(hidden_size, hidden_size) * 0.1\n",
    "        self.bh = np.zeros((hidden_size, 1))\n",
    "\n",
    "        # Output layer\n",
    "        self.Wy = np.random.randn(output_size, hidden_size) * 0.1\n",
    "        self.by = np.zeros((output_size, 1))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        h = np.zeros((self.hidden_size, 1))\n",
    "        self.cache = []\n",
    "\n",
    "        for x in inputs:\n",
    "            x = x.reshape(-1, 1)\n",
    "            z = sigmoid(self.Wz @ x + self.Uz @ h + self.bz)\n",
    "            r = sigmoid(self.Wr @ x + self.Ur @ h + self.br)\n",
    "            h_tilde = tanh(self.Wh @ x + self.Uh @ (r * h) + self.bh)\n",
    "            h_next = (1 - z) * h + z * h_tilde\n",
    "            self.cache.append((x, h.copy(), z, r, h_tilde))\n",
    "            h = h_next\n",
    "\n",
    "        self.h_last = h\n",
    "        y = self.Wy @ h + self.by\n",
    "        self.y_pred = y\n",
    "        return y\n",
    "\n",
    "    def backward(self, target):\n",
    "        dy = self.y_pred - target.reshape(-1, 1)\n",
    "        dWy = dy @ self.h_last.T\n",
    "        dby = dy\n",
    "        dh_next = self.Wy.T @ dy\n",
    "\n",
    "        dWz = np.zeros_like(self.Wz)\n",
    "        dUz = np.zeros_like(self.Uz)\n",
    "        dbz = np.zeros_like(self.bz)\n",
    "\n",
    "        dWr = np.zeros_like(self.Wr)\n",
    "dUr = np.zeros_like(self.Ur)\n",
    "dbr = np.zeros_like(self.br)\n",
    "\n",
    "dWh = np.zeros_like(self.Wh)\n",
    "dUh = np.zeros_like(self.Uh)\n",
    "dbh = np.zeros_like(self.bh)\n",
    "\n",
    "\n",
    "        for t in reversed(range(len(self.cache))):\n",
    "            x, h_prev, z, r, h_tilde = self.cache[t]\n",
    "            x = x.reshape(-1, 1)\n",
    "\n",
    "            dh = dh_next\n",
    "            dz = dh * (h_tilde - h_prev)\n",
    "            dh_tilde = dh * z\n",
    "            dh_prev = dh * (1 - z)\n",
    "\n",
    "            dz_raw = dz * dsigmoid(self.Wz @ x + self.Uz @ h_prev + self.bz)\n",
    "            dWz += dz_raw @ x.T\n",
    "            dUz += dz_raw @ h_prev.T\n",
    "            dbz += dz_raw\n",
    "\n",
    "            h_tilde_input = self.Wh @ x + self.Uh @ (r * h_prev) + self.bh\n",
    "            dh_tilde_raw = dh_tilde * dtanh(h_tilde_input)\n",
    "            dWh += dh_tilde_raw @ x.T\n",
    "            dUh += dh_tilde_raw @ (r * h_prev).T\n",
    "            dbh += dh_tilde_raw\n",
    "\n",
    "            dr = (self.Uh @ dh_tilde_raw) * h_prev\n",
    "            dr_raw = dr * dsigmoid(self.Wr @ x + self.Ur @ h_prev + self.br)\n",
    "            dWr += dr_raw @ x.T\n",
    "            dUr += dr_raw @ h_prev.T\n",
    "            dbr += dr_raw\n",
    "\n",
    "            dh_prev = (\n",
    "                dh_prev\n",
    "                + self.Uz.T @ dz_raw\n",
    "                + self.Ur.T @ dr_raw\n",
    "                + r * (self.Uh.T @ dh_tilde_raw)\n",
    "            )\n",
    "            dh_next = dh_prev\n",
    "\n",
    "        self.Wy -= self.lr * dWy\n",
    "        self.by -= self.lr * dby\n",
    "        for param, grad in zip(\n",
    "            [self.Wz, self.Uz, self.bz, self.Wr, self.Ur, self.br, self.Wh, self.Uh, self.bh],\n",
    "            [dWz, dUz, dbz, dWr, dUr, dbr, dWh, dUh, dbh]\n",
    "        ):\n",
    "            param -= self.lr * grad\n",
    "\n",
    "    def train(self, X, y, epochs=10):\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            for i in range(len(X)):\n",
    "                y_pred = self.forward(X[i])\n",
    "                loss = np.sum((y_pred - y[i].reshape(-1, 1)) ** 2)\n",
    "                total_loss += loss\n",
    "                self.backward(y[i])\n",
    "            print(f\"Epoch {epoch+1}, Loss: {total_loss / len(X):.4f}\")\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        y = self.forward(inputs)\n",
    "        return y\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    np.random.seed(42)\n",
    "    input_size = 3\n",
    "    hidden_size = 4\n",
    "    output_size = 1\n",
    "    sequence_length = 5\n",
    "\n",
    "    gru = GRU(input_size, hidden_size, output_size, lr=0.01)\n",
    "\n",
    "    # Generate synthetic binary classification data\n",
    "    X_train = [[np.random.randn(input_size) for _ in range(sequence_length)] for _ in range(100)]\n",
    "    y_train = [np.array([1 if sum(seq[-1]) > 0 else 0]) for seq in X_train]\n",
    "\n",
    "    # Train model\n",
    "    gru.train(X_train, y_train, epochs=20)\n",
    "\n",
    "    # Predict\n",
    "    test_seq = [np.random.randn(input_size) for _ in range(sequence_length)]\n",
    "    output = gru.predict(test_seq)\n",
    "    print(\"Predicted value:\", output[0][0])\n",
    "    print(\"Predicted class:\", int(output[0][0] > 0.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b91b281-99eb-4d7a-8490-64a808849539",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
