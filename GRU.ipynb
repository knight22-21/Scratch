{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5baa705e-488d-4322-b627-fd08278e57ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.3934\n",
      "Epoch 2, Loss: 0.2553\n",
      "Epoch 3, Loss: 0.2362\n",
      "Epoch 4, Loss: 0.2306\n",
      "Epoch 5, Loss: 0.2253\n",
      "Epoch 6, Loss: 0.2187\n",
      "Epoch 7, Loss: 0.2104\n",
      "Epoch 8, Loss: 0.2004\n",
      "Epoch 9, Loss: 0.1890\n",
      "Epoch 10, Loss: 0.1766\n",
      "Epoch 11, Loss: 0.1639\n",
      "Epoch 12, Loss: 0.1517\n",
      "Epoch 13, Loss: 0.1405\n",
      "Epoch 14, Loss: 0.1307\n",
      "Epoch 15, Loss: 0.1225\n",
      "Epoch 16, Loss: 0.1158\n",
      "Epoch 17, Loss: 0.1103\n",
      "Epoch 18, Loss: 0.1058\n",
      "Epoch 19, Loss: 0.1022\n",
      "Epoch 20, Loss: 0.0992\n",
      "Predicted value: 0.7473167047360891\n",
      "Predicted class: 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def dsigmoid(x):\n",
    "    s = sigmoid(x)\n",
    "    return s * (1 - s)\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def dtanh(x):\n",
    "    return 1 - tanh(x) ** 2\n",
    "\n",
    "class GRU:\n",
    "    def __init__(self, input_size, hidden_size, output_size, lr=0.01):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.lr = lr\n",
    "\n",
    "        # Update gate\n",
    "        self.Wz = np.random.randn(hidden_size, input_size) * 0.1\n",
    "        self.Uz = np.random.randn(hidden_size, hidden_size) * 0.1\n",
    "        self.bz = np.zeros((hidden_size, 1))\n",
    "\n",
    "        # Reset gate\n",
    "        self.Wr = np.random.randn(hidden_size, input_size) * 0.1\n",
    "        self.Ur = np.random.randn(hidden_size, hidden_size) * 0.1\n",
    "        self.br = np.zeros((hidden_size, 1))\n",
    "\n",
    "        # Candidate hidden state\n",
    "        self.Wh = np.random.randn(hidden_size, input_size) * 0.1\n",
    "        self.Uh = np.random.randn(hidden_size, hidden_size) * 0.1\n",
    "        self.bh = np.zeros((hidden_size, 1))\n",
    "\n",
    "        # Output layer\n",
    "        self.Wy = np.random.randn(output_size, hidden_size) * 0.1\n",
    "        self.by = np.zeros((output_size, 1))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        h = np.zeros((self.hidden_size, 1))\n",
    "        self.cache = []\n",
    "\n",
    "        for x in inputs:\n",
    "            x = x.reshape(-1, 1)\n",
    "            z = sigmoid(self.Wz @ x + self.Uz @ h + self.bz)\n",
    "            r = sigmoid(self.Wr @ x + self.Ur @ h + self.br)\n",
    "            h_tilde = tanh(self.Wh @ x + self.Uh @ (r * h) + self.bh)\n",
    "            h_next = (1 - z) * h + z * h_tilde\n",
    "            self.cache.append((x, h.copy(), z, r, h_tilde))\n",
    "            h = h_next\n",
    "\n",
    "        self.h_last = h\n",
    "        y = self.Wy @ h + self.by\n",
    "        self.y_pred = y\n",
    "        return y\n",
    "\n",
    "    def backward(self, target):\n",
    "        dy = self.y_pred - target.reshape(-1, 1)\n",
    "        dWy = dy @ self.h_last.T\n",
    "        dby = dy\n",
    "        dh_next = self.Wy.T @ dy\n",
    "\n",
    "        dWz = np.zeros_like(self.Wz)\n",
    "        dUz = np.zeros_like(self.Uz)\n",
    "        dbz = np.zeros_like(self.bz)\n",
    "\n",
    "        dWr = np.zeros_like(self.Wr)\n",
    "        dUr = np.zeros_like(self.Ur)\n",
    "        dbr = np.zeros_like(self.br)\n",
    "\n",
    "        dWh = np.zeros_like(self.Wh)\n",
    "        dUh = np.zeros_like(self.Uh)\n",
    "        dbh = np.zeros_like(self.bh)\n",
    "\n",
    "\n",
    "        for t in reversed(range(len(self.cache))):\n",
    "            x, h_prev, z, r, h_tilde = self.cache[t]\n",
    "            x = x.reshape(-1, 1)\n",
    "\n",
    "            dh = dh_next\n",
    "            dz = dh * (h_tilde - h_prev)\n",
    "            dh_tilde = dh * z\n",
    "            dh_prev = dh * (1 - z)\n",
    "\n",
    "            dz_raw = dz * dsigmoid(self.Wz @ x + self.Uz @ h_prev + self.bz)\n",
    "            dWz += dz_raw @ x.T\n",
    "            dUz += dz_raw @ h_prev.T\n",
    "            dbz += dz_raw\n",
    "\n",
    "            h_tilde_input = self.Wh @ x + self.Uh @ (r * h_prev) + self.bh\n",
    "            dh_tilde_raw = dh_tilde * dtanh(h_tilde_input)\n",
    "            dWh += dh_tilde_raw @ x.T\n",
    "            dUh += dh_tilde_raw @ (r * h_prev).T\n",
    "            dbh += dh_tilde_raw\n",
    "\n",
    "            dr = (self.Uh @ dh_tilde_raw) * h_prev\n",
    "            dr_raw = dr * dsigmoid(self.Wr @ x + self.Ur @ h_prev + self.br)\n",
    "            dWr += dr_raw @ x.T\n",
    "            dUr += dr_raw @ h_prev.T\n",
    "            dbr += dr_raw\n",
    "\n",
    "            dh_prev = (\n",
    "                dh_prev\n",
    "                + self.Uz.T @ dz_raw\n",
    "                + self.Ur.T @ dr_raw\n",
    "                + r * (self.Uh.T @ dh_tilde_raw)\n",
    "            )\n",
    "            dh_next = dh_prev\n",
    "\n",
    "        self.Wy -= self.lr * dWy\n",
    "        self.by -= self.lr * dby\n",
    "        for param, grad in zip(\n",
    "            [self.Wz, self.Uz, self.bz, self.Wr, self.Ur, self.br, self.Wh, self.Uh, self.bh],\n",
    "            [dWz, dUz, dbz, dWr, dUr, dbr, dWh, dUh, dbh]\n",
    "        ):\n",
    "            param -= self.lr * grad\n",
    "\n",
    "    def train(self, X, y, epochs=10):\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            for i in range(len(X)):\n",
    "                y_pred = self.forward(X[i])\n",
    "                loss = np.sum((y_pred - y[i].reshape(-1, 1)) ** 2)\n",
    "                total_loss += loss\n",
    "                self.backward(y[i])\n",
    "            print(f\"Epoch {epoch+1}, Loss: {total_loss / len(X):.4f}\")\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        y = self.forward(inputs)\n",
    "        return y\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    np.random.seed(42)\n",
    "    input_size = 3\n",
    "    hidden_size = 4\n",
    "    output_size = 1\n",
    "    sequence_length = 5\n",
    "\n",
    "    gru = GRU(input_size, hidden_size, output_size, lr=0.01)\n",
    "\n",
    "    # Generate synthetic binary classification data\n",
    "    X_train = [[np.random.randn(input_size) for _ in range(sequence_length)] for _ in range(100)]\n",
    "    y_train = [np.array([1 if sum(seq[-1]) > 0 else 0]) for seq in X_train]\n",
    "\n",
    "    # Train model\n",
    "    gru.train(X_train, y_train, epochs=20)\n",
    "\n",
    "    # Predict\n",
    "    test_seq = [np.random.randn(input_size) for _ in range(sequence_length)]\n",
    "    output = gru.predict(test_seq)\n",
    "    print(\"Predicted value:\", output[0][0])\n",
    "    print(\"Predicted class:\", int(output[0][0] > 0.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b91b281-99eb-4d7a-8490-64a808849539",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
