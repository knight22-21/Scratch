{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16af9558-d889-45af-a393-fbb0626b10b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def dsigmoid(x):\n",
    "    s = sigmoid(x)\n",
    "    return s * (1 - s)\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def dtanh(x):\n",
    "    return 1 - np.tanh(x) ** 2\n",
    "\n",
    "class LSTM:\n",
    "    def __init__(self, input_size, hidden_size, output_size, lr=0.01):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.lr = lr\n",
    "\n",
    "        concat_size = input_size + hidden_size\n",
    "        def init_weights(): return np.random.randn(hidden_size, concat_size) * 0.1\n",
    "        def init_bias(): return np.zeros((hidden_size, 1))\n",
    "\n",
    "        self.Wf, self.bf = init_weights(), init_bias()\n",
    "        self.Wi, self.bi = init_weights(), init_bias()\n",
    "        self.Wc, self.bc = init_weights(), init_bias()\n",
    "        self.Wo, self.bo = init_weights(), init_bias()\n",
    "\n",
    "        self.Wy = np.random.randn(output_size, hidden_size) * 0.1\n",
    "        self.by = np.zeros((output_size, 1))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        h = np.zeros((self.hidden_size, 1))\n",
    "        c = np.zeros((self.hidden_size, 1))\n",
    "        self.cache = []\n",
    "\n",
    "        for xt in inputs:\n",
    "            xt = xt.reshape(-1, 1)\n",
    "            concat = np.vstack((h, xt))\n",
    "\n",
    "            ft = sigmoid(self.Wf @ concat + self.bf)\n",
    "            it = sigmoid(self.Wi @ concat + self.bi)\n",
    "            c_hat = tanh(self.Wc @ concat + self.bc)\n",
    "            c = ft * c + it * c_hat\n",
    "            ot = sigmoid(self.Wo @ concat + self.bo)\n",
    "            h = ot * tanh(c)\n",
    "\n",
    "            self.cache.append((xt, concat, ft, it, c_hat, c, ot, h))\n",
    "\n",
    "        y = self.Wy @ h + self.by\n",
    "        return y, h\n",
    "\n",
    "    def backward(self, target):\n",
    "        dWy = np.zeros_like(self.Wy)\n",
    "        dby = np.zeros_like(self.by)\n",
    "\n",
    "        dWf = np.zeros_like(self.Wf)\n",
    "        dWi = np.zeros_like(self.Wi)\n",
    "        dWc = np.zeros_like(self.Wc)\n",
    "        dWo = np.zeros_like(self.Wo)\n",
    "\n",
    "        dbf = np.zeros_like(self.bf)\n",
    "        dbi = np.zeros_like(self.bi)\n",
    "        dbc = np.zeros_like(self.bc)\n",
    "        dbo = np.zeros_like(self.bo)\n",
    "\n",
    "        dy = self.y_pred - target\n",
    "        last_h = self.cache[-1][-1]\n",
    "        dWy += dy @ last_h.T\n",
    "        dby += dy\n",
    "\n",
    "        dh_next = self.Wy.T @ dy\n",
    "        dc_next = np.zeros_like(dh_next)\n",
    "\n",
    "        for t in reversed(range(len(self.cache))):\n",
    "            xt, concat, ft, it, c_hat, c, ot, h = self.cache[t]\n",
    "            c_prev = self.cache[t - 1][5] if t > 0 else np.zeros_like(c)\n",
    "\n",
    "            do = dh_next * tanh(c)\n",
    "            dOt_raw = do * dsigmoid(self.Wo @ concat + self.bo)\n",
    "            dWo += dOt_raw @ concat.T\n",
    "            dbo += dOt_raw\n",
    "\n",
    "            dc = dh_next * ot * dtanh(c) + dc_next\n",
    "            dc_hat = dc * it\n",
    "            dc_hat_raw = dc_hat * dtanh(self.Wc @ concat + self.bc)\n",
    "            dWc += dc_hat_raw @ concat.T\n",
    "            dbc += dc_hat_raw\n",
    "\n",
    "            di = dc * c_hat\n",
    "            dIt_raw = di * dsigmoid(self.Wi @ concat + self.bi)\n",
    "            dWi += dIt_raw @ concat.T\n",
    "            dbi += dIt_raw\n",
    "\n",
    "            df = dc * c_prev\n",
    "            dFt_raw = df * dsigmoid(self.Wf @ concat + self.bf)\n",
    "            dWf += dFt_raw @ concat.T\n",
    "            dbf += dFt_raw\n",
    "\n",
    "            d_concat = (\n",
    "                self.Wf.T @ dFt_raw +\n",
    "                self.Wi.T @ dIt_raw +\n",
    "                self.Wc.T @ dc_hat_raw +\n",
    "                self.Wo.T @ dOt_raw\n",
    "            )\n",
    "            dh_next = d_concat[:self.hidden_size, :]\n",
    "            dc_next = dc * ft\n",
    "\n",
    "        # Gradient descent update\n",
    "        for W, dW in zip(\n",
    "            [self.Wf, self.Wi, self.Wc, self.Wo, self.Wy],\n",
    "            [dWf, dWi, dWc, dWo, dWy]\n",
    "        ):\n",
    "            W -= self.lr * dW\n",
    "\n",
    "        for b, db in zip(\n",
    "            [self.bf, self.bi, self.bc, self.bo, self.by],\n",
    "            [dbf, dbi, dbc, dbo, dby]\n",
    "        ):\n",
    "            b -= self.lr * db\n",
    "\n",
    "    def train(self, X_train, y_train, epochs=10):\n",
    "        for epoch in range(epochs):\n",
    "            loss = 0\n",
    "            for x_seq, y_true in zip(X_train, y_train):\n",
    "                self.y_pred, _ = self.forward(x_seq)\n",
    "                loss += np.sum((self.y_pred - y_true.reshape(-1, 1)) ** 2)\n",
    "                self.backward(y_true.reshape(-1, 1))\n",
    "            avg_loss = loss / len(X_train)\n",
    "            print(f\"Epoch {epoch+1}: Loss = {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57b005f8-8988-42a8-b6b7-76b8892e2331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 0.3382\n",
      "Epoch 2: Loss = 0.2578\n",
      "Epoch 3: Loss = 0.2462\n",
      "Epoch 4: Loss = 0.2432\n",
      "Epoch 5: Loss = 0.2411\n",
      "Epoch 6: Loss = 0.2390\n",
      "Epoch 7: Loss = 0.2366\n",
      "Epoch 8: Loss = 0.2340\n",
      "Epoch 9: Loss = 0.2311\n",
      "Epoch 10: Loss = 0.2279\n",
      "Epoch 11: Loss = 0.2244\n",
      "Epoch 12: Loss = 0.2206\n",
      "Epoch 13: Loss = 0.2165\n",
      "Epoch 14: Loss = 0.2121\n",
      "Epoch 15: Loss = 0.2075\n",
      "Epoch 16: Loss = 0.2026\n",
      "Epoch 17: Loss = 0.1975\n",
      "Epoch 18: Loss = 0.1923\n",
      "Epoch 19: Loss = 0.1869\n",
      "Epoch 20: Loss = 0.1816\n",
      "Test Prediction (raw): [[0.6210284]]\n",
      "Predicted Label: 1\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    np.random.seed(42)\n",
    "\n",
    "    input_size = 3\n",
    "    hidden_size = 4\n",
    "    output_size = 1\n",
    "    seq_len = 5\n",
    "\n",
    "    model = LSTM(input_size, hidden_size, output_size, lr=0.01)\n",
    "\n",
    "    # Generate synthetic training data\n",
    "    X_train = [[np.random.randn(input_size) for _ in range(seq_len)] for _ in range(100)]\n",
    "    y_train = [np.array([1 if sum(x[-1]) > 0 else 0]) for x in X_train]  # Label depends on last input\n",
    "\n",
    "    model.train(X_train, y_train, epochs=20)\n",
    "\n",
    "    # Test\n",
    "    test_seq = [np.random.randn(input_size) for _ in range(seq_len)]\n",
    "    prediction, _ = model.forward(test_seq)\n",
    "    print(\"Test Prediction (raw):\", prediction)\n",
    "    print(\"Predicted Label:\", int(prediction[0][0] > 0.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8b2310-dbce-4280-87db-ef9f22e40695",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
